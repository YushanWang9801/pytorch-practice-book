import torch
import numpy as np

print("=" * 40)
print("ğŸ“¦ åŸºæœ¬ Tensor åˆ›å»º")
print("=" * 40)

x = torch.tensor([[1.0, 2.0], [3.0, 4.0]])
zeros = torch.zeros((2, 3))
ones = torch.ones((2, 2))
rand = torch.rand((2, 2))
eye = torch.eye(3)
like = torch.ones_like(x)

print(
    f"x:\n{x}\nzeros:\n{zeros}\nones:\n{ones}\nrand:\n{rand}\neye:\n{eye}\nlike:\n{like}"
)

print("=" * 40)
print("ğŸ” NumPy â†” Tensor")
print("=" * 40)

a = np.array([[1, 2], [3, 4]])
t = torch.from_numpy(a)
a[0, 0] = 99
print("å…±äº«å†…å­˜ç¤ºä¾‹ï¼š", t)

t2 = torch.tensor([[5.0, 6.0]])
n = t2.numpy()
print("è½¬æ¢ä¸º NumPyï¼š", n)

print("=" * 40)
print("ğŸ§ª Tensor åŸºæœ¬æ“ä½œ")
print("=" * 40)

x = torch.tensor([[1, 2], [3, 4]], dtype=torch.float32)
y = torch.tensor([[5, 6], [7, 8]], dtype=torch.float32)

print("åŠ æ³•:", x + y)
print("é€å…ƒç´ ä¹˜æ³•:", x * y)
print("çŸ©é˜µä¹˜æ³•:", torch.matmul(x, y))

print("=" * 40)
print("ğŸ”„ Tensor ç»´åº¦å˜åŒ–")
print("=" * 40)

x = torch.arange(12).reshape(3, 4)
print("åŸå§‹ x:\n", x)

x_reshaped = x.view(4, 3)
x_unsqueeze = x.unsqueeze(0)
x_squeezed = x_unsqueeze.squeeze()
print("reshape:", x_reshaped.shape)
print("unsqueeze:", x_unsqueeze.shape)
print("squeeze:", x_squeezed.shape)

print("=" * 40)
print("ğŸ§® è‡ªåŠ¨æ±‚å¯¼åŸºç¡€")
print("=" * 40)

x = torch.tensor(2.0, requires_grad=True)
y = x**2 + 3 * x + 1
y.backward()
print("dy/dx:", x.grad)  # 2x + 3 = 7

print("=" * 40)
print("â›“ï¸ å¤šæ­¥é“¾å¼åå‘ä¼ æ’­")
print("=" * 40)

a = torch.tensor(1.0, requires_grad=True)
b = a * 2
c = b**2 + 3
c.backward()
print("dc/da =", a.grad)

print("=" * 40)
print("ğŸ¯ å¤šå˜é‡è‡ªåŠ¨æ±‚å¯¼ï¼ˆä¿ç•™å›¾ï¼‰")
print("=" * 40)

x = torch.tensor(1.0, requires_grad=True)
y = torch.tensor(2.0, requires_grad=True)
z = x * y + y**2
z.backward(retain_graph=True)  # å¯é‡å¤ backward
print("dz/dx =", x.grad)
print("dz/dy =", y.grad)

# å†æ¬¡ backwardï¼ˆæ¢¯åº¦ä¼šç´¯åŠ ï¼‰
z.backward()
print("å†æ¬¡ backward å dz/dx =", x.grad)

# æ¸…é™¤æ¢¯åº¦
x.grad.zero_()
y.grad.zero_()

print("=" * 40)
print("ğŸ“Œ ä½¿ç”¨ torch.autograd.grad æ‰‹åŠ¨è·å–æ¢¯åº¦")
print("=" * 40)

x = torch.tensor(3.0, requires_grad=True)
y = x**3 + 2 * x
grad = torch.autograd.grad(y, x)
print("dy/dx:", grad)

print("=" * 40)
print("ğŸ§Š detach å’Œ requires_grad_ çš„æŠ€å·§")
print("=" * 40)

a = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)
b = a * 2
c = b.detach()  # åˆ†ç¦»è®¡ç®—å›¾
print("c æ˜¯å¦éœ€è¦ gradï¼š", c.requires_grad)

a.requires_grad_(False)
print("a.requires_grad=False:", a.requires_grad)

print("=" * 40)
print("ğŸš€ GPU å¯ç”¨æ€§æ£€æµ‹")
print("=" * 40)

print("CUDA æ˜¯å¦å¯ç”¨:", torch.cuda.is_available())
if torch.cuda.is_available():
    device = torch.device("cuda")
    t = torch.tensor([1.0, 2.0], device=device)
    print("å½“å‰è®¾å¤‡:", t.device)
else:
    print("ä½¿ç”¨ CPU")
